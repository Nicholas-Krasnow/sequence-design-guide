{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011483b6",
   "metadata": {},
   "source": [
    "Filter the Blast hits for >50% coverage and >30% identity. count the residues at each position of the BoNT/F alignment. Write a function to generate a list of residues with conservation above a specified cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5464b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ff323",
   "metadata": {},
   "source": [
    "Import the fasta file for your target protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fasta = list(SeqIO.parse('BoNT_X.fasta','fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = target_fasta[0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b512d7",
   "metadata": {},
   "source": [
    "Import the data table output (.tsv) of the initial blast search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d6f37-3a32-4d2b-ba6f-b20085994882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BoNTX_out_-4.tsv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac766f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_titles = ['query','id','match','length','mismatch','gapopen','qstart','qend','sstart','send','Eval','bitscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c02ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = column_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_length = len(target_fasta[0].seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ec6a1-b72c-45fb-9c64-fa14fc125eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ids = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['match'] > 30:\n",
    "        coverage = (prot_length)/2\n",
    "        if row['length'] > coverage:\n",
    "            filtered_ids.append(row['id'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97353508-f9f3-42ae-b83b-0ef1d228eb65",
   "metadata": {},
   "source": [
    "analyzed the filtered sequences. Import the .fasta file of Blast hit sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6eb025-297a-4581-a7df-42a65711a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_fasta = list(SeqIO.parse('X_hits_seqs.fasta','fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474903b1-9afd-48f3-925b-6b3354198f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_seqs = {}\n",
    "entries = []\n",
    "entries.append(target_fasta[0]) #add BoNT/E to the top\n",
    "\n",
    "for record in blast_fasta:\n",
    "    if record.id in filtered_ids:\n",
    "        filtered_seqs[record.id] = record.seq\n",
    "        entries.append(record)\n",
    "        \n",
    "SeqIO.write(entries, \"filtered_hits.fasta\", \"fasta\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952a052-3b87-4c3a-962c-7cc2f6d39fc8",
   "metadata": {},
   "source": [
    "Make MSA from the fasta file. The next steps will make a multiple sequence aligment with clustal omega. If you don't have clustal omega installed you can make the multiple alignment of the filtered_hits.fasta using Geneious, move the file to this directory, then skip ahead to the next note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830e376-9a4f-4a30-ab17-41507595cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Align.Applications import ClustalOmegaCommandline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9da295-dd42-4e63-a86e-c21bfd770fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import AlignIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef489c2-09a2-433d-89e5-0b61e4a02de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustalomega_cline = ClustalOmegaCommandline(infile='filtered_hits.fasta', outfile='filtered_aligned.fasta',force=True)\n",
    "clustalomega_cline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfe56e",
   "metadata": {},
   "source": [
    "Skip to this step if you aligned in Geneious and import the file you generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting alignment file\n",
    "alignment = AlignIO.read('filtered_aligned.fasta', \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7f00d-122e-4c24-bc78-2971be59da5a",
   "metadata": {},
   "source": [
    "Add up the counts of each non-gap AA at each position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c591014-261c-40aa-8bed-adfd5ed83815",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_dict = {}\n",
    "for pos in range(alignment.get_alignment_length()):\n",
    "    dict = {}\n",
    "    for i in range(len(alignment)):\n",
    "        if alignment[i][pos] != '-':\n",
    "            if alignment[i][pos] not in dict:\n",
    "                dict[alignment[i][pos]] = 1\n",
    "            else:\n",
    "                dict[alignment[i][pos]] += 1\n",
    "    \n",
    "    positions_dict[pos] = dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109883e-8383-4645-b5ad-1084cc7e4960",
   "metadata": {},
   "source": [
    "Determine the fraction consensus and most abundant AA (not including gaps in count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eebc670-4317-4817-a6e2-a1e8e6dc80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = []\n",
    "consensus_AA = []\n",
    "for i in range(len(positions_dict)):\n",
    "    key_with_highest_value = max(positions_dict[i], key=lambda key: positions_dict[i][key])\n",
    "    consensus_AA.append(key_with_highest_value)\n",
    "    \n",
    "    total = 0\n",
    "    for value in positions_dict[i].values():\n",
    "        total += value\n",
    "    consensus.append(max(positions_dict[i].values())/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccdbfdd-f52f-4f7e-9d8c-a77783cdb00b",
   "metadata": {},
   "source": [
    "copy in the distance-constrained residue list that you calculated in pyrosetta (colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_fixed_res = [23,\n",
    " 24,\n",
    " 25,\n",
    " 26,\n",
    " 27,\n",
    " 28,\n",
    " 34,\n",
    " 35,\n",
    " 36,\n",
    " 54,\n",
    " 55,\n",
    " 56,\n",
    " 57,\n",
    " 58,\n",
    " 59,\n",
    " 60,\n",
    " 60,\n",
    " 69,\n",
    " 70,\n",
    " 71,\n",
    " 72,\n",
    " 73,\n",
    " 74,\n",
    " 75,\n",
    " 76,\n",
    " 124,\n",
    " 132,\n",
    " 133,\n",
    " 134,\n",
    " 135,\n",
    " 136,\n",
    " 137,\n",
    " 158,\n",
    " 159,\n",
    " 160,\n",
    " 161,\n",
    " 162,\n",
    " 163,\n",
    " 164,\n",
    " 165,\n",
    " 166,\n",
    " 167,\n",
    " 168,\n",
    " 169,\n",
    " 170,\n",
    " 171,\n",
    " 172,\n",
    " 172,\n",
    " 172,\n",
    " 172,\n",
    " 173,\n",
    " 174,\n",
    " 175,\n",
    " 176,\n",
    " 177,\n",
    " 179,\n",
    " 180,\n",
    " 181,\n",
    " 182,\n",
    " 183,\n",
    " 184,\n",
    " 185,\n",
    " 186,\n",
    " 187,\n",
    " 192,\n",
    " 193,\n",
    " 223,\n",
    " 224,\n",
    " 225,\n",
    " 226,\n",
    " 227,\n",
    " 228,\n",
    " 229,\n",
    " 230,\n",
    " 231,\n",
    " 232,\n",
    " 233,\n",
    " 234,\n",
    " 235,\n",
    " 236,\n",
    " 238,\n",
    " 239,\n",
    " 240,\n",
    " 241,\n",
    " 242,\n",
    " 243,\n",
    " 244,\n",
    " 244,\n",
    " 245,\n",
    " 246,\n",
    " 247,\n",
    " 248,\n",
    " 249,\n",
    " 250,\n",
    " 252,\n",
    " 254,\n",
    " 257,\n",
    " 258,\n",
    " 259,\n",
    " 260,\n",
    " 261,\n",
    " 262,\n",
    " 263,\n",
    " 264,\n",
    " 265,\n",
    " 266,\n",
    " 267,\n",
    " 268,\n",
    " 269,\n",
    " 270,\n",
    " 271,\n",
    " 274,\n",
    " 275,\n",
    " 348,\n",
    " 360,\n",
    " 361,\n",
    " 362,\n",
    " 363,\n",
    " 364,\n",
    " 365,\n",
    " 366,\n",
    " 367,\n",
    " 368,\n",
    " 422,\n",
    " 29,\n",
    " 30,\n",
    " 31,\n",
    " 32,\n",
    " 33]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04b597",
   "metadata": {},
   "source": [
    "Define the function to choose residues to fix based on selected conservation cutoffs and combine with the distance constraint list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd7576-28ac-493f-9287-0ac0ce5f83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(cutoffList,distance_cutoff):\n",
    "    output_dict = {}\n",
    "\n",
    "    #choose conserved residues to fix based on cutoff\n",
    "    for cutoff in cutoffList:\n",
    "        fixed_cons = []\n",
    "        x = 0\n",
    "        sequence = str(alignment[0].seq)\n",
    "        for i,res in enumerate(sequence):\n",
    "            if res != '-':\n",
    "                x += 1\n",
    "                if res == consensus_AA[i]:\n",
    "                    if consensus[i] >= cutoff:\n",
    "                        fixed_cons.append(x)\n",
    "    \n",
    "        frac = len(fixed_cons)/len(target_fasta[0].seq)\n",
    "    \n",
    "        #make list of the fixed residues from distance or conservation requirement\n",
    "        all_fixed_residues = []\n",
    "        for x in fixed_cons:\n",
    "            all_fixed_residues.append(x)\n",
    "        for y in PDB_fixed_res:\n",
    "            if y not in all_fixed_residues:\n",
    "                all_fixed_residues.append(y)\n",
    "                \n",
    "        #for z in man_fixed_res:\n",
    "         #   if z not in all_fixed_residues:\n",
    "          #      all_fixed_residues.append(z)\n",
    "                \n",
    "        all_fixed_residues.sort()\n",
    "        \n",
    "        frac_all_fixed = len(all_fixed_residues)/len(target_fasta[0].seq)\n",
    "\n",
    "        all_fixed_res_str = ''\n",
    "        for i in all_fixed_residues:\n",
    "            all_fixed_res_str= all_fixed_res_str + str(i) + ' '\n",
    "    \n",
    "        #pymol commands to select residues\n",
    "        pymol_command_conserve = 'select conserve, chain A and resi '\n",
    "        for x in fixed_cons:\n",
    "          pymol_command_conserve = pymol_command_conserve + str(x) + '+'\n",
    "    \n",
    "        pymol_command_bind = 'select bind, chain A and resi '\n",
    "        for x in PDB_fixed_res:\n",
    "          pymol_command_bind = pymol_command_bind + str(x) + '+'\n",
    "    \n",
    "        #pymol_command_man = 'select manual, chain A and resi '\n",
    "        #for x in man_fixed_res:\n",
    "          #pymol_command_man = pymol_command_man + str(x) + '+'\n",
    "\n",
    "        output_dict[cutoff] = [all_fixed_res_str,all_fixed_residues, fixed_cons,frac, frac_all_fixed, pymol_command_conserve, pymol_command_bind]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(output_dict)\n",
    "    cols = ['MPNN fix string','all fixed','fixed by conservation','fraction fixed by conservation','fraction all res fixed','pymol conserved','pymol bind']\n",
    "    df=df.T\n",
    "    df.columns=cols\n",
    "    df.to_csv(name+'_'+str(distance_cutoff)+'_constraints.csv')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963759df",
   "metadata": {},
   "source": [
    "Run the function with your desired inputs. The first argument is a list of your conservation cutoffs (30% and 60% in the example) and the second argument is the distance cutoff you used in your distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84547788-ab5a-4bdb-bd95-cba237f1dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_res([.3, .6],14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2cd22",
   "metadata": {},
   "source": [
    "A csv file should have been generated with the list of fixed residues for each conservation cutoff and the particular distance cutoff. To generate constraints for different distance cutoffs, rerun this script with the distance-constrained residue lists you generated for those cutoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd7e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
